{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Main.ipynb","provenance":[],"authorship_tag":"ABX9TyOgXw7nVIIe3L2+SgCTAgOu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"eYrn0JX8vO_P"},"outputs":[],"source":["\"\"\"\n","@author: Chenggang\n","@github: https://github.com/MissShihongHowRU\n","@time: 2020-09-09 22:04\n","\"\"\"\n","import os\n","\n","os.environ['PYTHONHASHSEED'] = '0'\n","\n","import sys\n","sys.path.append(\".\")\n","\n","import numpy as np\n","import random\n","# torch.cuda.empty_cache()\n","import torch\n","torch.cuda.empty_cache()\n","import os\n","from torch import nn\n","from torch import optim\n","from torch.optim import lr_scheduler\n","from utils import Logger, load_old_model, poly_lr_scheduler\n","from train import train_epoch\n","from validation import val_epoch\n","from metrics import CombinedLoss, SoftDiceLoss\n","from dataset import BratsDataset\n","import argparse\n","from config import config\n","# from torch.cuda.amp import autocast\n","# from torch.cuda.amp import GradScaler\n","# set seed\n","seed_num = 64\n","np.random.seed(seed_num)\n","random.seed(seed_num)\n","# import kora hoilo\n","\n","\n","def init_args():\n","# function call kore argparser korse\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument('--batch_size', type=int, help='The batch size of the test images', default=2)\n","    parser.add_argument('-e', '--epoch', type=str, help='The number of epochs of training', default=100)\n","    parser.add_argument('-l', '--patch_size', type=str, help='Patch size of the input image', default=128)\n","    parser.add_argument('-g', '--num_gpu', type=int, help='Can be 0, 1, 2, 4', default=2)\n","    # parser.add_argument('-a', '--attention', type=int, help='whether to use attention blocks, 0, 1, 2', default=0)\n","    # parser.add_argument('--concat', type=bool, help='whether to use add & concatnate connection', default=False)\n","    parser.add_argument('-c', '--combine', type=bool, help='whether to use newSoftDiceLoss 1+2+4', default=False)\n","    # parser.add_argument('-d', '--dropout', type=bool, help='whether to add one dropout layer within each DownSampling operation', default=False)\n","    parser.add_argument('-f', '--flooding', type=bool, help='whether to apply flooding strategy during training', default=False)\n","    parser.add_argument('--seglabel', type=int, help='whether to train the model with 1 or all 3 labels', default=0)\n","    parser.add_argument('-t', '--act', type=int, help='activation function, choose between 0 and 1; 0-ReLU; 1-Sin', default=0)\n","    parser.add_argument('-s', '--save_folder', type=str, help='The folder for model saving', default='saved_pth')\n","    parser.add_argument('-p', '--pth', type=str, help='name of the saved pth file', default='')\n","    parser.add_argument('-i', '--image_shape', type=int,  nargs='+', help='The shape of input tensor;'\n","                                                                    'have to be dividable by 16 (H, W, D)',\n","                        default=[128,192,160])\n","\n","    return parser.parse_args()\n","\n","args = init_args() ## ei line e arg_parser gulo call korse\n","num_epoch = args.epoch # epoch define\n","num_gpu = args.num_gpu # koita Gpu\n","batch_size = args.batch_size # batch size koto define\n","# batch_size = 1\n","new_SoftDiceLoss = args.combine # loss_function define kora hoilo\n","dropout = args.dropout  #drop_out koto seta\n","flooding = args.flooding # flooding nibo kina\n","seglabel_idx = args.seglabel # seglabel_idx er value koto seta\n","label_list = [None, \"WT\", \"TC\", \"ET\"]   # None represents using all 3 labels\n","dice_list = [None, \"dice_wt\", \"dice_tc\", \"dice_et\"] \n","seg_label = label_list[seglabel_idx]  # used for data generation\n","seg_dice = dice_list[seglabel_idx]  # used for dice calculation\n","# activation_list = [\"relu\", \"sin\"] # Activation function change kore\n","\n","# activation = activation_list[args.act]\n","save_folder = args.save_folder # ei folder e save hbe\n","\n","pth_name = args.pth\n","\n","image_shape = tuple(args.image_shape) #image_shape define\n","\n","concat = args.concat\n","attention_idx = args.attention\n","\n","# attention = True\n","# if attention_idx == 0:\n","#     if concat:\n","#         from nvnet_cat import NvNet # basically eta call hbe\n","#     elif dropout:\n","#         from nvnet_dropout import NvNet\n","#     else:\n","#         from merge_nvnet import NvNet\n","#     attention = False\n","# elif attention_idx == 1:\n","#     from attVnet import AttentionVNet\n","# elif attention_idx == 2:\n","#     if dropout:\n","#         from attVnet_v2_dropout import AttentionVNet\n","#     else:\n","#         from attVnet_v2 import AttentionVNet\n","\n","config[\"cuda_devices\"] = True\n","if num_gpu == 0:\n","    config[\"cuda_devices\"] = None\n","elif num_gpu == 1:\n","    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" # eta select hbe\n","elif num_gpu == 2:\n","    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n","elif num_gpu == 4:\n","    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\"\n","\n","config[\"batch_size\"] = batch_size # batch size\n","config[\"validation_batch_size\"] = batch_size \n","\n","config[\"model_name\"] = \"TransBTS-bs{}\".format(config[\"batch_size\"]) #model name save hbe # logger\n","\n","config[\"image_shape\"] = image_shape #image_shape define\n","# config[\"activation\"] = activation #activation \n","\n","config[\"input_shape\"] = tuple([config[\"batch_size\"]] + [config[\"nb_channels\"]] + list(config[\"image_shape\"]))\n","# input shape hbe (bs,channel,image shape)\n","\n","config[\"result_path\"] = os.path.join(config[\"base_path\"], \"models\", save_folder)  \n","#training folder/models folder/ # save models and status files\n","# config[\"saved_model_file\"] = '/Users/missshihonghowru/Desktop/nyu master/brats-challenge/pth-models_status/model.pth'\n","config[\"saved_model_file\"] = config[\"result_path\"] + pth_name \n","config[\"overwrite\"] = True\n","if pth_name:\n","    config[\"overwrite\"] = False\n","\n","config[\"epochs\"] = int(num_epoch)\n","# config[\"attention\"] = attention\n","config[\"seg_label\"] = seg_label # 0 diye korbo                            # used for data generation\n","config[\"num_labels\"] = 1 if config[\"seg_label\"] else 3 #3 assign hbe     # used for model constructing\n","config[\"seg_dice\"] = seg_dice     #None                          # used for dice calculation\n","config[\"new_SoftDiceLoss\"] = new_SoftDiceLoss\n","#using all 3 labels train hbe\n","\n","config[\"flooding\"] = flooding\n","if config[\"flooding\"]:\n","    config[\"flooding_level\"] = 0.15\n","\n","\n","def main(): # main function start holo ekhane\n","    # init or load model\n","    print(\"init model with input shape\", config[\"input_shape\"])\n","    # if config[\"attention\"]:\n","    #     model = AttentionVNet(config=config)\n","    #     print(model)\n","    # else:\n","    # model = NvNet(config=config)\n","    _,model = TransBTS(dataset='brats', _conv_repr=True, _pe_type=\"learned\")\n","    print(model) #model ekhane call hbe.\n","    parameters = model.parameters()\n","    print(f\"Parameters: {parameters}\") # model parameters\n","    optimizer = optim.Adam(parameters, \n","                           lr=config[\"initial_learning_rate\"], 1e-4\n","                           weight_decay=config[\"L2_norm\"]) 1e-5\n","    start_epoch = 1\n","    # if config[\"VAE_enable\"]:\n","    #     loss_function = CombinedLoss(new_loss=config[\"new_SoftDiceLoss\"],\n","    #                                  k1=config[\"loss_k1_weight\"], k2=config[\"loss_k2_weight\"],\n","    #                                  alpha=config[\"focal_alpha\"], gamma=config[\"focal_gamma\"],\n","    #                                  focal_enable=config[\"focal_enable\"])\n","    # else:\n","    loss_function = SoftDiceLoss(new_loss=config[\"new_SoftDiceLoss\"])\n","        #loss_function defined holo\n","\n","    with open('/content/gdrive/MyDrive/2Stage_VAE/Dataset/BraTS2020_TrainingData/valid_list.txt', 'r') as f:\n","        val_list = f.read().splitlines()\n","    # with open('train_list.txt', 'r') as f:\n","    with open('/content/gdrive/MyDrive/2Stage_VAE/Dataset/BraTS2020_TrainingData/train_list.txt', 'r') as f:\n","        train_list = f.read().splitlines()\n","\n","    config[\"training_patients\"] = tr_list\n","    config[\"validation_patients\"] = val_list\n","    train_root = config['train_dir']\n","    # data_generator\n","    print(\"data generating\")\n","    training_data = BraTS(train_list, train_root,'train')\n","    # x = training_data[0] # for test\n","    valildation_data = BraTS(val_list, train_root,'valid')\n","    train_logger = Logger(model_name=config[\"model_name\"] + '.h5',\n","                          header=['epoch', 'loss', 'wt-dice', 'tc-dice', 'et-dice', 'lr'])\n","\n","    if not config[\"overwrite\"] and config[\"saved_model_file\"] is not None:\n","        if not os.path.exists(config[\"saved_model_file\"]):\n","            raise Exception(\"Invalid model path!\")\n","        model, start_epoch, optimizer_resume = load_old_model(model, optimizer, saved_model_path=config[\"saved_model_file\"])\n","        parameters = model.parameters()\n","        optimizer = optim.Adam(parameters,\n","                               lr=optimizer_resume.param_groups[0][\"lr\"],\n","                               weight_decay=optimizer_resume.param_groups[0][\"weight_decay\"])\n","\n","    if config[\"cuda_devices\"] is not None:\n","        model = model.cuda()\n","        loss_function = loss_function.cuda()\n","        model = nn.DataParallel(model)    # multi-gpu training\n","        for state in optimizer.state.values():\n","\t        for k, v in state.items():\n","\t            if isinstance(v, torch.Tensor):\n","\t                state[k] = v.cuda()\n","\n","    # scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=config[\"lr_decay\"], patience=config[\"patience\"])\n","    scheduler = lr_scheduler.LambdaLR(optimizer=optimizer, lr_lambda=poly_lr_scheduler)  # can't restore lr correctly\n","    #LR scheduler define\n","    max_val_WT_dice = 0.\n","    max_val_AVG_dice = 0.\n","    # scaler = GradScaler()\n","    # gradient_accumulations = 4\n","    # model.zero_grad()\n","    for i in range(start_epoch, config[\"epochs\"]):\n","        train_epoch(epoch=i, \n","                    data_set=training_data, \n","                    model=model,\n","                    criterion=loss_function, \n","                    optimizer=optimizer, \n","                    opt=config, \n","                    logger=train_logger) \n","        \n","        val_loss, WT_dice, TC_dice, ET_dice = val_epoch(epoch=i,\n","                    data_set=valildation_data,\n","                    model=model,\n","                    criterion=loss_function,\n","                    opt=config,\n","                    optimizer=optimizer,\n","                    logger=train_logger)\n","\n","        scheduler.step()\n","        # scheduler.step(val_loss)\n","        dices = np.array([WT_dice, TC_dice, ET_dice])\n","        AVG_dice = dices.mean()\n","        if config[\"checkpoint\"] and (WT_dice > max_val_WT_dice or AVG_dice > max_val_AVG_dice or WT_dice >= 0.912):\n","            max_val_WT_dice = WT_dice\n","            max_val_AVG_dice = AVG_dice\n","            # save_dir = os.path.join(config[\"result_path\"], config[\"model_file\"].split(\"/\")[-1].split(\".h5\")[0])\n","            save_dir = config[\"result_path\"]\n","            if not os.path.exists(save_dir):\n","                os.makedirs(save_dir)\n","            save_states_path = os.path.join(save_dir, 'epoch_{0}_val_loss_{1:.4f}_WTdice_{2:.4f}_AVGDice:{3:.4f}.pth'.format(i, val_loss, WT_dice, AVG_dice))\n","            if config[\"cuda_devices\"] is not None:\n","                state_dict = model.module.state_dict()\n","            else:\n","                state_dict = model.state_dict()\n","            states = {\n","                'epoch': i,\n","                'state_dict': state_dict,\n","                'optimizer': optimizer.state_dict(),\n","            }\n","            torch.save(states, save_states_path)\n","            save_model_path = os.path.join(save_dir, \"best_model.pth\")\n","            if os.path.exists(save_model_path):\n","                os.system(\"rm \"+save_model_path)\n","            torch.save(model, save_model_path)\n","        print(\"batch {0:d} finished, validation loss:{1:.4f}; WTDice:{2:.4f}; AVGDice:{3:.4f}\".format(i, val_loss, WT_dice, AVG_dice))\n","\n","if __name__ == '__main__':\n","    main()\n"]}]}