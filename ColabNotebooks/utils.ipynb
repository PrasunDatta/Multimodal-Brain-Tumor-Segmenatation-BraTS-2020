{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"utils.ipynb","provenance":[],"authorship_tag":"ABX9TyN+/grpfZnjJC5fkXcR4zPC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"AGW-p0D1w8Xv"},"outputs":[],"source":["####attempt\n","\n","\"\"\"\n","@author: Chenggang\n","@github: https://github.com/MissShihongHowRU\n","@time: 2020-09-09 22:04\n","\"\"\"\n","import pickle\n","import torch\n","import tensorboardX\n","import numpy as np\n","from collections import OrderedDict\n","import SimpleITK as sitk\n","\n","def pickle_load(in_file):\n","    with open(in_file, \"rb\") as opened_file:\n","        return pickle.load(opened_file)\n","\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","class Logger(object):\n","\n","    def __init__(self, model_name, header):\n","        self.header = header\n","        self.writer = tensorboardX.SummaryWriter(\"./runs/\"+model_name.split(\"/\")[-1].split(\".h5\")[0])\n","\n","    def __del(self):\n","        self.writer.close()\n","\n","    def log(self, phase, values):\n","        epoch = values['epoch']\n","        \n","        for col in self.header[1:]:\n","            self.writer.add_scalar(phase+\"/\"+col, float(values[col]), int(epoch))\n","\n","\n","def load_value_file(file_path):\n","    with open(file_path, 'r') as input_file:\n","        value = float(input_file.read().rstrip('\\n\\r'))\n","\n","    return value\n","\n","\n","def combine_labels(labels):\n","    \"\"\"\n","    Combine wt, tc, et into WT; tc, et into TC; et into ET\n","    :param labels: torch.Tensor of size (bs, 3, ?,?,?); ? is the crop size\n","    :return:\n","    \"\"\"\n","    whole_tumor = labels[:, :3, :, :, :].sum(1)  # could have 2 or 3\n","    tumor_core = labels[:, 1:3, :, :, :].sum(1)\n","    enhanced_tumor = labels[:, 2:3, :, :, :].sum(1)\n","    whole_tumor[whole_tumor != 0] = 1\n","    tumor_core[tumor_core != 0] = 1\n","    enhanced_tumor[enhanced_tumor != 0] = 1\n","    return whole_tumor, tumor_core, enhanced_tumor  # (bs, ?, ?, ?)\n","\n","\n","def calculate_accuracy(outputs, targets):\n","    return dice_coefficient(outputs, targets)\n","\n","\n","def dice_coefficient(outputs, targets, threshold=0.5, eps=1e-8):  # 搞三个dice看 每个label; 不要做soft dice\n","    # batch_size = targets.size(0)\n","    y_pred = outputs[:, :3, :, :, :]  # targets[0,:3,:,:,:]\n","    y_truth = targets[:, :3, :, :, :]\n","    y_pred = y_pred > threshold\n","    y_pred = y_pred.type(torch.FloatTensor)\n","    wt_pred, tc_pred, et_pred = combine_labels(y_pred)\n","    wt_truth, tc_truth, et_truth = combine_labels(y_truth)\n","    res = dict()\n","    res[\"dice_wt\"] = dice_coefficient_single_label(wt_pred, wt_truth, eps)\n","    res[\"dice_tc\"] = dice_coefficient_single_label(tc_pred, tc_truth, eps)\n","    res[\"dice_et\"] = dice_coefficient_single_label(et_pred, et_truth, eps)\n","\n","    return res\n","\n","\n","def calculate_accuracy_singleLabel(outputs, targets, threshold=0.5, eps=1e-8):\n","\n","    y_pred = outputs[:, 0, :, :, :]  # targets[0,:3,:,:,:]\n","    y_truth = targets[:, 0, :, :, :]\n","    y_pred = y_pred > threshold\n","    y_pred = y_pred.type(torch.FloatTensor)\n","    res = dice_coefficient_single_label(y_pred, y_truth, eps)\n","    return res\n","\n","\n","def dice_coefficient_single_label(y_pred, y_truth, eps):\n","    # batch_size = y_pred.size(0)\n","    intersection = torch.sum(torch.mul(y_pred, y_truth), dim=(-3, -2, -1)) + eps / 2  # axis=?, (bs, 1)\n","    union = torch.sum(y_pred, dim=(-3,-2,-1)) + torch.sum(y_truth, dim=(-3,-2,-1)) + eps  # (bs, 1)\n","    dice = 2 * intersection / union\n","    return dice.mean()\n","    # return dice / batch_size\n","\n","\n","def load_old_model(model, optimizer, saved_model_path, data_paralell=True):\n","    print(\"Constructing model from saved file... \")\n","    checkpoint = torch.load(saved_model_path, map_location='cpu')\n","    epoch = checkpoint[\"epoch\"]\n","    if data_paralell:\n","        state_dict = OrderedDict()\n","        for k, v in checkpoint[\"state_dict\"].items():  # remove \"module.\"\n","            if \"module.\" in k:\n","                node_name = k[7:]\n","\n","            else:\n","                node_name = k\n","            state_dict[node_name] = v\n","        model.load_state_dict(state_dict)\n","    else:\n","        model.load_state_dict(checkpoint[\"state_dict\"])\n","    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n","\n","    return model, epoch, optimizer\n","\n","\n","def combine_labels_predicting(output_array):\n","    \"\"\"\n","    # (1, 3, 240, 240, 155)\n","    :param output_array: output of the model containing 3 seperated labels (3 channels)\n","    :return: res_array: conbined labels (1 channel)\n","    \"\"\"\n","    shape = output_array.shape[-3:]\n","    if len(output_array.shape) == 5:\n","        bs = output_array.shape[0]\n","        res_array = np.zeros((bs, ) + shape)\n","        res_array[output_array[:, 0, :, :, :] == 1] = 2  # 1\n","        res_array[output_array[:, 1, :, :, :] == 1] = 1  # 2\n","        res_array[output_array[:, 2, :, :, :] == 1] = 4\n","    elif len(output_array.shape) == 4:\n","        res_array = np.zeros(shape)\n","        res_array[output_array[0, :, :, :] == 1] = 2\n","        res_array[output_array[1, :, :, :] == 1] = 1\n","        res_array[output_array[2, :, :, :] == 1] = 4\n","    return res_array\n","\n","\n","def dim_recovery(img_array, orig_shape=(155, 240, 240)):\n","    \"\"\"\n","    used when doing inference\n","    :param img_array:\n","    :param orig_shape:\n","    :return:\n","    \"\"\"\n","    crop_shape = np.array(img_array.shape[-3:])\n","    center = np.array(orig_shape) // 2\n","    lower_limits = center - crop_shape // 2\n","    upper_limits = center + crop_shape // 2\n","    if len(img_array.shape) == 5:\n","        bs, num_labels = img_array.shape[:2]\n","        res_array = np.zeros((bs, num_labels) + orig_shape)\n","        res_array[:, :, lower_limits[0]: upper_limits[0],\n","                        lower_limits[1]: upper_limits[1], lower_limits[2]: upper_limits[2]] = img_array\n","    if len(img_array.shape) == 4:\n","        num_labels = img_array.shape[0]\n","        res_array = np.zeros((num_labels, ) + orig_shape)\n","        res_array[:, lower_limits[0]: upper_limits[0],\n","                     lower_limits[1]: upper_limits[1], lower_limits[2]: upper_limits[2]] = img_array\n","\n","    if len(img_array.shape) == 3:\n","        res_array = np.zeros(orig_shape)\n","        res_array[lower_limits[0]: upper_limits[0],\n","            lower_limits[1]: upper_limits[1], lower_limits[2]: upper_limits[2]] = img_array\n","\n","    return res_array\n","\n","\n","def convert_stik_to_nparray(gz_path):\n","    sitkImage = sitk.ReadImage(gz_path)\n","    nparray = sitk.GetArrayFromImage(sitkImage)\n","    return nparray\n","\n","\n","def poly_lr_scheduler(epoch, num_epochs=300, power=0.9): \n","  #num_epochs ta adjust kora lagbe.\n","    return (1 - epoch/num_epochs)**power"]}]}